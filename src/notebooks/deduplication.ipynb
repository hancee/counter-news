{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General use\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Notebook behavior\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "seed = 19  # Replicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get env\n",
    "from src.lib.utils.env_checker import running_environment\n",
    "env = running_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "fname = \"cleaned_events.parquet\"\n",
    "if env==\"sagemaker\":\n",
    "    df = pd.read_parquet(f\"s3://news-s3/data/cleaned/{fname}\")\n",
    "else:\n",
    "    df = pd.read_parquet(f\"../../data/{fname}\").fillna(np.nan)\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to 14 days\n",
    "lim = df[\"SQLDATE\"].drop_duplicates().sort_values(ascending=False)[14]\n",
    "df = df[df[\"SQLDATE\"]>=lim]\n",
    "df = df.drop(columns=[\"SQLDATE\"], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe\n",
    "df.describe()\n",
    "df.describe(include=\"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data prep prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique IDs\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning- ensure values are normalized\n",
    "# Capitalize all str cols\n",
    "str_cols = df.select_dtypes(include=\"O\")\n",
    "for str_col in str_cols:\n",
    "    df[str_col] = df[str_col].str.strip().str.upper().str.normalize(\"NFKD\").str.encode(\"ascii\", errors=\"ignore\").str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null-handling\n",
    "# Note: Splink treats null values differently from empty strings, so using true nulls guarantees proper matching across datasets.\n",
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the linker\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "settings = {\"link_type\": \"dedupe_only\", \"unique_id_column_name\":\"GLOBALEVENTID\"}\n",
    "linker = DuckDBLinker(df, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for sparsity\n",
    "import altair as alt\n",
    "linker.missingness_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile\n",
    "linker.profile_columns(top_n=10, bottom_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.duckdb.blocking_rule_library import block_on\n",
    "blocking_rules = [\n",
    "    block_on([\"QuadClass\", \"Actor1CountryCode\", \"Actor2CountryCode\"]), \n",
    "    block_on([\"Actor1Name\", \"Actor2Name\"]), \n",
    "]\n",
    "\n",
    "{blocking_rule.blocking_rule_sql:linker.count_num_comparisons_from_blocking_rule(blocking_rule) for blocking_rule in blocking_rules}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much of initial comparison space will now be compared\n",
    "n_base_comparisons = (df.shape[0]**2) - df.shape[0]  # Without blocking rule\n",
    "n_comparisons = np.sum([linker.count_num_comparisons_from_blocking_rule(blocking_rule) for blocking_rule in blocking_rules])\n",
    "np.round(n_comparisons / n_base_comparisons, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update settings\n",
    "settings[\"blocking_rules_to_generate_predictions\"] = blocking_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Estimating Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not levenshtein because we don't expect mispellings\n",
    "from splink.duckdb import comparison_library as cl\n",
    "from splink.duckdb import comparison_template_library as ctl\n",
    "comparisons = [\n",
    "    # ctl.date_comparison(\"EventDateTime\", datediff_thresholds=[7], datediff_metrics=[\"day\"])\n",
    "    cl.datediff_at_thresholds(\"EventDateTime\", date_metrics=[\"day\"], date_thresholds=[7]), \n",
    "    cl.jaro_winkler_at_thresholds(\"Actor1Geo_FullName\", 0.8, term_frequency_adjustments=True), \n",
    "    cl.jaro_winkler_at_thresholds(\"Actor2Geo_FullName\", 0.8, term_frequency_adjustments=True), \n",
    "    ctl.name_comparison(\"Actor1Name\"), \n",
    "    ctl.name_comparison(\"Actor2Name\"), \n",
    "    cl.levenshtein_at_thresholds(\"Actor1Code\", 3, term_frequency_adjustments=True), \n",
    "    cl.levenshtein_at_thresholds(\"Actor2Code\", 3, term_frequency_adjustments=True), \n",
    "    cl.exact_match(\"CAMEOEvent\", term_frequency_adjustments=True), \n",
    "]\n",
    "settings[\"comparisons\"] = comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model-based settings\n",
    "settings[\"retain_matching_columns\"] = True\n",
    "settings[\"retain_intermediate_calculation_columns\"] = True\n",
    "settings[\"max_iterations\"] = 20\n",
    "settings[\"em_convergence\"] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate new linker based on updated settings\n",
    "linker = DuckDBLinker(\"df\", settings)\n",
    "linker.estimate_probability_two_random_records_match(\n",
    "    blocking_rules,\n",
    "    recall=0.8,\n",
    ")\n",
    "linker.estimate_u_using_random_sampling(max_pairs=1e9)\n",
    "\n",
    "# Note: IndexError is a bug (https://github.com/moj-analytical-services/splink/issues/2076#issuecomment-2007755672)\n",
    "# Sol'n: cona install sqlglot=22.5.0\n",
    "feature = \"GoldsteinScore\"\n",
    "# linker.estimate_parameters_using_expectation_maximisation(\n",
    "#     f\"abs(l.{feature} - r.{feature}) <= {np.round(df[feature].std()/2, 4)}\", \n",
    "# )\n",
    "linker.estimate_parameters_using_expectation_maximisation(\n",
    "    block_on([\"Actor1Name\", \"QuadClass\"]), \n",
    "    estimate_without_term_frequencies=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predicting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "threshold = 0.95\n",
    "pred = linker.predict(threshold_match_probability=threshold)\n",
    "pred_df = pred.as_pandas_dataframe()\n",
    "\n",
    "clusters = linker.cluster_pairwise_predictions_at_threshold(\n",
    "    pred, threshold_match_probability=threshold\n",
    ").as_pandas_dataframe()\n",
    "\n",
    "n_pairwise_comparisons = (\n",
    "    linker.count_num_comparisons_from_blocking_rules_for_prediction(\n",
    "        pred\n",
    "    ).as_pandas_dataframe(limit=None)\n",
    ").count_of_edges.sum()\n",
    "n_base_comparisons, n_comparisons, n_pairwise_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model parameters\n",
    "linker.m_u_parameters_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://www.robinlinacre.com/fast_deduplication/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clusters[clusters[\"cluster_id\"]==clusters[\"cluster_id\"].value_counts().index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import splink.duckdb.comparison_library as cl\n",
    "import splink.duckdb.comparison_template_library as ctl\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"unique_id_column_name\":\"GLOBALEVENTID\", \n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on([\"QuadClass\", \"Actor1CountryCode\", \"Actor2CountryCode\"]), \n",
    "    ],\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"Actor1Name\", term_frequency_adjustments=True),\n",
    "        ctl.name_comparison(\"Actor2Name\", term_frequency_adjustments=True),\n",
    "        cl.levenshtein_at_thresholds(\"Actor1Geo_FullName\", [1, 2]),\n",
    "        cl.datediff_at_thresholds(\"EventDateTime\", ), \n",
    "        cl.jaro_at_thresholds(\"full_name\", [0.9, 0.7], term_frequency_adjustments=True),\n",
    "        cl.levenshtein_at_thresholds(\"dob\", [1, 2]),\n",
    "        cl.levenshtein_at_thresholds(\"postcode_fake\", 2),\n",
    "        cl.jaro_winkler_at_thresholds(\"birth_place\", 0.9, term_frequency_adjustments=True),\n",
    "        cl.exact_match(\"occupation\",  term_frequency_adjustments=True),\n",
    "    ],           \n",
    "\n",
    "    'comparison_levels': [\n",
    "    {\n",
    "        'sql_condition': '\"date_of_birth_l\" IS NULL OR \"date_of_birth_r\" IS NULL',\n",
    "        'label_for_charts': 'Null',\n",
    "        'is_null_level': True\n",
    "    },\n",
    "    \"comparisons\": [\n",
    "        ctl.date_comparison(\"EventDateTime\", cast_strings_to_date=True, )\n",
    "        ctl.name_comparison(\"first_name\"),\n",
    "        ctl.name_comparison(\"surname\"),\n",
    "        ctl.date_comparison(\"dob\", cast_strings_to_date=True),\n",
    "        cl.exact_match(\"city\", term_frequency_adjustments=True),\n",
    "        ctl.email_comparison(\"email\", include_username_fuzzy_level=False),\n",
    "    ],\"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "}\n",
    "\n",
    "linker = DuckDBLinker(df, settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
