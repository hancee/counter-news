{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General use\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import uuid\n",
    "from src.lib.utils.path_finder import PROJECT_DIRECTORY\n",
    "from src.lib.utils.config import config\n",
    "\n",
    "# Notebook behavior\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "seed = config[\"SEED\"]  # Replicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(PROJECT_DIRECTORY.joinpath(\"data/raw/bq-results-20240316-113951-1710589244204.csv\"), dtype={\"GLOBALEVENTID\":str, \"MentionIdentifier\":str, \"QuadClass\":str, \"CAMEOEventRoot\":str, \"CAMEOEventBase\":str, \"CAMEOEvent\":str})\n",
    "df = pd.DataFrame({\"uuid\":[uuid.uuid4() for _ in range(len(df))]}).merge(df, left_index=True, right_index=True).set_index(\"uuid\", drop=True)\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read docs\n",
    "docs = pd.read_parquet(PROJECT_DIRECTORY.joinpath(\"data/cleaned/cleaned_docs.parquet\"))\n",
    "docs.shape\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate events\n",
    "# Initial assumption: GLOBALEVENTID should be unique\n",
    "df[\"GLOBALEVENTID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check where duplicates are coming from\n",
    "# Findings: these are events that get multiple first-reports hence multiple documents associated with it. This can be \n",
    "ids_ = df[\"GLOBALEVENTID\"].value_counts()[df[\"GLOBALEVENTID\"].value_counts()>1].index.tolist()\n",
    "tmp = df[df[\"GLOBALEVENTID\"].isin(ids_)].pivot_table(index=\"GLOBALEVENTID\", aggfunc=lambda ser: ser.nunique()>1)\n",
    "tmp.sum()[tmp.sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate event-relevant from reporting-relevant attributes\n",
    "event_attrs = [c for c in df.columns if c not in tmp.sum()[tmp.sum()>0].index.tolist()]\n",
    "reporting_attrs = tmp.sum()[tmp.sum()>0].index.tolist()\n",
    "assert df.shape[1] == len(event_attrs) + len(reporting_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe\n",
    "# Reason: First mention of same event per document is retained when we drop duplicates\n",
    "df = df.sort_values([\"GLOBALEVENTID\", \"MentionIdentifier\", \"SentenceID\"], ascending=[True, True, True]).drop_duplicates([\"GLOBALEVENTID\", \"MentionIdentifier\"], keep=\"first\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate event details\n",
    "event_report_map = df[[\"GLOBALEVENTID\", \"MentionIdentifier\"]]\n",
    "events = df[event_attrs].drop_duplicates()\n",
    "event_report_map.shape, events.shape, docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique events are mentioned in a single report?\n",
    "vc = df[\"MentionIdentifier\"].value_counts()\n",
    "vc.describe()\n",
    "_ = sns.kdeplot(vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Event Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview\n",
    "events = events.set_index(\"GLOBALEVENTID\", drop=True)  # Reindex\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "conflict_codes = [\"QuadClass\", \"CAMEOEventRoot\", \"CAMEOEventBase\", \"CAMEOEvent\"]\n",
    "assert np.all(events[conflict_codes].isna().sum()==0)  # Ensure there are no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nulls in GoldsteinScore\n",
    "# According to GDELT Documentation, GoldsteinScore is mapped from CAMEOEvent\n",
    "df[\"GoldsteinScore\"].isna().sum()\n",
    "df[\"GoldsteinScore\"] = df.groupby(\"CAMEOEvent\")[\"GoldsteinScore\"].transform(lambda x: x.fillna(x.mean()))  # Impute by getting mean of GoldsteinScore for the same CAMEOEvent\n",
    "df[\"GoldsteinScore\"] = df[\"GoldsteinScore\"].fillna(\"bfill\")  # If no CAMEOEvent with GoldsteinScore, use last valid value\n",
    "df[\"GoldsteinScore\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each feature against GoldsteinScore\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20,8), sharex=True)\n",
    "\n",
    "for i, group in enumerate(conflict_codes):\n",
    "    ax = axes[i//2, i%2]\n",
    "    _ = sns.kdeplot(data=events.sort_values(group, ascending=True), x=\"GoldsteinScore\", hue=group, fill=True, legend=False, ax=ax)\n",
    "    _ = ax.set_title(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rank correlation to identify conflict col that has the weakest association with  GoldsteinScore\n",
    "# Consistent with visualization above, it's CAMEOEvent has the weakest and QuadClass has the strongest. Note that the differences between the 4 are actually minimal\n",
    "from scipy.stats import spearmanr\n",
    "alpha = 0.01\n",
    "tmp = {}\n",
    "for conflict_code in conflict_codes:\n",
    "    p, frac = np.nan, 2**6/100\n",
    "    while pd.isna(p) and (frac>=0.01):\n",
    "        frac = frac / 2\n",
    "        events_ = events.sample(frac=frac, random_state=seed)\n",
    "        rho, p = spearmanr(events_[conflict_code], (events_[\"GoldsteinScore\"]))\n",
    "    tmp[conflict_code] = {\"frac\":frac, \"rho\":rho, \"p\":p, \"stat_sig\":p<alpha}\n",
    "pd.DataFrame.from_dict(tmp, orient=\"index\").sort_values(\"p\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of selected event-based attributes\n",
    "selected_event_attrs = [\"GoldsteinScore\", \"CAMEOEvent\"]\n",
    "blocking_rule_attrs = [\"QuadClass\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview date-relevant attributes\n",
    "event_dates = [\"SQLDATE\", \"FractionDate\", \"EventTimeDate\"]\n",
    "events[event_dates].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EventTimeDate is the most granular\n",
    "# When does a story get old?\n",
    "# Chakraborty et. al., 2021: 141.77 hours for NYTimes for highest lifetime impact\n",
    "chakraborty_estimate = 141.77\n",
    "np.round(chakraborty_estimate/24, 2)  # Equivalent to how many days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect by datetime component\n",
    "tmp = events[\"EventTimeDate\"].astype(str).str.extract(\"(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})\").astype(int)\n",
    "tmp.columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\"]\n",
    "tmp.head()  # Preview\n",
    "tmp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <ul>\n",
    "        <li>Based on Chakraborty et. al. (2021) study, a news story has optimal balance between recency and relevance within 5.91 days.</li>\n",
    "        <li>Among the datetime-relevant features from GDELT, EventDateTime is most granular and can be compared against Chakraborty et. al. estimate.</li>\n",
    "        <li>EventDateTime is the most granular but the second attribute has no variance.</li>\n",
    "        <li>Splink deduper supports this comparison between datetime objects based on their <a href=\"https://moj-analytical-services.github.io/splink/topic_guides/comparisons/customising_comparisons.html#date-comparison\">documentation</a>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime object\n",
    "events[\"EventDateTime\"] = pd.to_datetime(events[\"EventTimeDate\"], format=\"%Y%m%d%H%M%S\")\n",
    "event_dates.append(\"EventDateTime\")\n",
    "event_attrs.append(\"EventDateTime\")\n",
    "events[event_dates].head()  # Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update list\n",
    "selected_event_attrs.append(\"EventDateTime\")\n",
    "blocking_rule_attrs.append(\"SQLDATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview\n",
    "actor_attrs = [attr for attr in event_attrs if attr[:5]==\"Actor\"]\n",
    "events[actor_attrs].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe\n",
    "events_ = events.astype(str)[actor_attrs].replace(\"nan\", np.nan)\n",
    "tmp = events_.describe().T\n",
    "tmp[\"maj_class_pct\"] = tmp[\"freq\"].div(tmp[\"count\"])\n",
    "tmp[\"sparsity\"] = events_.isna().mean()\n",
    "\n",
    "# View actors 1 and 2 separately\n",
    "tmp[tmp.index.str[5]==\"1\"].sort_values(\"sparsity\")\n",
    "tmp[tmp.index.str[5]==\"2\"].sort_values(\"sparsity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for independence\n",
    "from src.lib.utils.helper_functions import test_for_independence\n",
    "# pairwise_comparison = lambda lst: sum([[(item, item_) for item_ in lst if item!=item_] for item in lst], [])\n",
    "pairwise_comparison = lambda lst: sum([[(item, item_) for item_ in lst[i:] if item!=item_] for i, item in enumerate(lst)], [])\n",
    "def get_pairwise_independence(df, features):\n",
    "    comparisons = pairwise_comparison(features)\n",
    "    results = {}\n",
    "    for x, y in comparisons:\n",
    "        series_x, series_y = df[x].fillna(\"__NULL__\"), df[y].fillna(\"__NULL__\")\n",
    "        frac, p = 1, np.nan\n",
    "        while pd.isna(p) & (frac<=0.01):\n",
    "            frac = frac/2\n",
    "            x_y_results = test_for_independence(series_x.sample(frac=frac, random_state=seed), series_y.sample(frac=frac, random_state=seed))\n",
    "            p = x_y_results[\"p\"]\n",
    "        results[(x , y, frac)] = test_for_independence(series_x.sample(frac=frac, random_state=seed), series_y.sample(frac=frac, random_state=seed))\n",
    "    return results\n",
    "\n",
    "actor1_attrs = tmp[(tmp.index.str[5]==\"1\") & (tmp[\"sparsity\"]<=0.5)].index.tolist()\n",
    "pd.DataFrame.from_dict(get_pairwise_independence(events, actor1_attrs), orient=\"index\").dropna().reset_index()\n",
    "\n",
    "actor2_attrs = tmp[(tmp.index.str[5]==\"2\") & (tmp[\"sparsity\"]<=0.5)].index.tolist()\n",
    "pd.DataFrame.from_dict(get_pairwise_independence(events, actor2_attrs), orient=\"index\").dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update list\n",
    "selected_event_actor_attrs = [\"Actor1Code\", \"Actor1Name\", \"Actor1Geo_FullName\", \"Actor2Code\", \"Actor2Name\", \"Actor2Geo_FullName\"]\n",
    "selected_event_attrs.extend(selected_event_actor_attrs)\n",
    "blocking_rule_attrs.extend([\"Actor1CountryCode\", \"Actor2CountryCode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for most common combinations\n",
    "events[selected_event_actor_attrs].fillna(\"__NULL__\").value_counts(normalize=True).head(20).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in separate df\n",
    "events_bu = events.copy()  # Back up original dataframe\n",
    "events = events[blocking_rule_attrs + selected_event_attrs]#.fillna(\"__NULL__\")\n",
    "events.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "events.to_parquet(PROJECT_DIRECTORY.joinpath(\"data/cleaned/cleaned_events.parquet\"), compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
